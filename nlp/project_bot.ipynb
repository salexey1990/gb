{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from telegram.ext  import Updater, CommandHandler, MessageHandler, Filters\n",
    "import dialogflow\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "updater = Updater(token='') # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/home/alex/Downloads/small-talk-gesu-809b2c029117.json'# скачнный JSON\n",
    "\n",
    "\n",
    "DIALOGFLOW_PROJECT_ID = 'small-talk-gesu' #PROJECT ID из DialogFlow \n",
    "DIALOGFLOW_LANGUAGE_CODE = 'ru' # язык\n",
    "SESSION_ID = 'gb_project_bot'  # ID бота из телеграма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим свой чат бот как комбинацию dialog_flow  и собственноручно написанной болталки. Для dialog_flow части выберем один из предобученных шаблонов - small-talk, который имеет расшиненный набор базовых интентов. В качаестве собственной болталки возьмём за основу чат из 2-й лекции, которую усовершенствуем, используя tfidf веса для формирования итогового вектора предложения, и увеличив количество ядер для annoy индекса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4629306ae81c4d8398cac276b82ff39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question = None\n",
    "written = False\n",
    "\n",
    "with open(\"/home/alex/Downloads/nlp/prepared_answers.txt\", \"w\") as fout:\n",
    "    with open(\"/home/alex/Downloads/nlp/Otvety.txt\", \"r\") as fin:\n",
    "        for line in tqdm_notebook(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7873119a6bd54884babcc1ea1cc0d9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "with open(\"/home/alex/Downloads/nlp/Otvety.txt\", \"r\") as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        spls = preprocess_txt(line)\n",
    "        sentences.append(spls)\n",
    "        c += 1\n",
    "        if c > 100000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [i for i in sentences if len(i) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText(sentences=sentences, size=200, min_count=2, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_tokenizer(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=identity_tokenizer,\n",
    "                                   lowercase=False, max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<64853x165803 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 951676 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed144c473714aaea8c553f9adeb96f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_index = annoy.AnnoyIndex(200 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(\"/home/alex/Downloads/nlp/prepared_answers.txt\", \"r\") as f:\n",
    "    for line in tqdm_notebook(f):\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        \n",
    "        vector_ft = np.zeros(200)\n",
    "        for word in question:\n",
    "            if word in modelFT:\n",
    "                vector_ft += modelFT[word]\n",
    "                n_ft += tfidf_vectorizer.idf_[tfidf_vectorizer.vocabulary_[word]] if word in tfidf_vectorizer.vocabulary_ else 1\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "\n",
    "ft_index.build(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(200)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            norm += tfidf_vectorizer.idf_[tfidf_vectorizer.vocabulary_[word]]\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 3)\n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startCommand(bot, update):\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='Добрый день')\n",
    "\n",
    "def textMessage(bot, update):\n",
    "\n",
    "    session_client = dialogflow.SessionsClient()\n",
    "    session = session_client.session_path(DIALOGFLOW_PROJECT_ID, SESSION_ID)\n",
    "    text_input = dialogflow.types.TextInput(text=update.message.text , language_code=DIALOGFLOW_LANGUAGE_CODE)\n",
    "    query_input = dialogflow.types.QueryInput(text=text_input)\n",
    "    try:\n",
    "        response = session_client.detect_intent(session=session, query_input=query_input)\n",
    "    except InvalidArgument:\n",
    "         raise\n",
    "\n",
    "    text = response.query_result.fulfillment_text\n",
    "    if text:\n",
    "        bot.send_message(chat_id=update.message.chat_id, text= response.query_result.fulfillment_text)\n",
    "    else:\n",
    "        custom_response = get_response(update.message.text, ft_index, modelFT, index_map)\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=custom_response[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Хендлеры\n",
    "start_command_handler = CommandHandler('start', startCommand)\n",
    "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "# Добавляем хендлеры в диспетчер\n",
    "dispatcher.add_handler(start_command_handler)\n",
    "dispatcher.add_handler(text_message_handler)\n",
    "# Начинаем поиск обновлений\n",
    "updater.start_polling(clean=True)\n",
    "# Останавливаем бота, если были нажаты Ctrl + C\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
